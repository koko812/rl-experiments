
# LEARNED.md v0.1 — 強化学習入門：CartPole を題材にした可視化と分析

## 🧠 背景

Stack Tower ゲームを強化学習で制御するには、状態・行動・報酬が複雑すぎるため、まずは OpenAI Gym の CartPole 環境を用いたシンプルな強化学習の理解と分析に取り組むことにした。

---

## ✅ 段階的な取り組み

### 1. CartPole のランダムプレイログ収集

- `gymnasium.make("CartPole-v1")` を使用
- ランダムな行動で500ステップ程度プレイし、`obs`, `action`, `reward`, `done` を JSON に保存
- 出力形式は `json` と `csv` に切り替え可能な設計にしておき、分析に応じて使い分けられるようにした

### 2. 観測ログの可視化（plot_cartpole_log.py）

- 左グラフ：ポール角度 (`obs[2]`) の時間変化（赤線は `done=True` の瞬間）
- 右グラフ：報酬の推移を可視化（最初はステップごとの `reward`）

### 3. エピソードごとの累積報酬の算出

- `done=True` を区切りとし、各エピソードで `reward` を合計
- エピソード単位での報酬の伸び方・変動を分析できるようにした

### 4. ステップ単位での「エピソード内累積報酬」へ変更

- より直感的に「どこでゲームオーバーになったか」を確認できるように修正
- `done=True` のたびに累積報酬をリセットすることで、グラフ上で階段のようなパターンが見えるようになった

---

## 📊 分析のための工夫

- `Path(__file__).resolve().parent.parent` を使って、どこから実行してもログが読めるようにパスを統一
- `done=True` の位置に `axvline` で可視的な区切りを入れることで、エピソードの構造が見やすくなった
- JSON ログには `step` や `obs`, `reward` の全履歴が含まれており、後からあらゆる可視化に再利用できる

---

## 🎯 現時点での知見・気づき

- `done=True` のタイミングを意識すると、ポールがどれだけ揺れていると倒れるかがだんだん見えてくる
- エピソードの累積報酬のグラフは、**学習が進んでいるかどうか**の評価にも直感的に使える
- 今後、ルールベースや学習エージェントと比較する際にもこのログがベースになる
- 分析や可視化の柔軟性を保つためにも、ログ出力は汎用的にしておくべき

---

## 🔜 次のステップ案

- ルールベース（if-else）エージェントを作って、ランダムと比較
- 学習エージェント（Q-Learning / DQN）導入前に、報酬設計・行動空間の理解を整理
- ログを `notebooks/analysis.ipynb` でより詳細に可視化
- CartPole の他に LunarLander も同様のログ化・可視化基盤に乗せる
